# X投稿文レビュースキル

## 役割
生成されたX投稿文をルールに照らしてレビューし、問題点を指摘・修正する。

## 入力
- ネタのタイトル/概要
- ネタの発表日/公開日
- 情報ソース（URL等）
- 生成された投稿文

---

## 一次情報チェック（CRITICAL - 最優先）

**❗ AIパワーユーザー向けの厳しい鮮度基準**
- X.comで四六時中情報追跡しているユーザーには3-4日前は「古いネタ」
- 表面的な「今日公開」情報は数日前の情報を記事化しただけの可能性高

**「記事の投稿日」≠「ニュースの初発表日」**

ソース元の記事が1日前でも、そのニュース内容が初発表されたのはいつかを確認する。

**確認手順**:
1. 記事内容の核心情報（機能発表、研究公開等）を特定
2. その情報の「初出」はいつかをWebSearchで調査
3. 初発表日が1日以内かどうかで判定

**例**:
- ❌ 記事投稿日: 1/23、だが「Personal Intelligence」の初発表は1/14 → **10日前のネタとして判定**
- ✅ 記事投稿日: 1/23、新機能の初発表も同日 → **1日以内のネタとして採用**

**「拡張ロールアウト」や「対応地域追加」は新ニュースではない**:
- 「日本でも利用可能に」→ 元の機能発表日が基準
- 「AI Modeにも拡張」→ 元の機能発表日が基準

---

## 鮮度判定（初発表日と今日の日付の差分）

| 経過日数 | 判定 | アクション |
|---------|------|-----------|
| 0-1日 | PASS（最優先） | そのまま採用可能 |
| 2-3日 | PASS | 採用可能 |
| 4-14日 | 深堀り判定必須 | 下記4項目をチェック |
| 14日以上 | REJECT | 即却下、別ネタ探し |

---

## 深堀り価値判定（4日以上の場合のみ）

以下の4項目を全てチェック:

1. **AIエージェントパワーユーザー向け新知見があるか？**
   - 単なるニュースではなく、実践的なTipsや深い分析があるか
   - 「知らなかった」と感じる情報があるか

2. **個人開発者に実用的な2次情報が出ているか？**
   - 元ニュースに対する実体験レポート、比較記事、チュートリアルがあるか
   - すぐに試せる具体的な手順があるか

3. **単なるニュースの焼き直しではないか？（厳格判定）**
   - 元記事/リリースノートと同じ内容をそのまま紹介するだけ → REJECT
   - 公式発表の数字をそのまま引用しただけ → REJECT（例: 「85%削減」だけでは不十分）
   - 技術用語の説明だけ → REJECT（例: 「lazy loading方式」の説明だけでは不十分）
   - **採用基準（以下のいずれかが必須）**:
     - 実際に使ってみた実体験レポートがある
     - **他ツールとの具体的数値比較**（ベンチマーク結果、87% vs 56%等）
     - **実導入事例・本番稼働実績**（Replit統合等「実はもう使われてる」系）
     - **AIパワーユーザーでも初見の切り口**（「精度だけで選ぶと見誤る」等の洞察）
     - 公式発表にない独自の検証結果がある
     - 実務での活用シーン/失敗談がある

4. **過去パッチ/過去バージョンのネタではないか？（CRITICAL）**
   - ソフトウェアのバージョンアップ系は「最新版」のみ採用
   - 例: Claude Code 2.1.7の機能 → 今は2.1.19なので却下
   - 過去パッチのネタは「よっぽど付加価値のある2次情報」がない限り却下

**判定結果:**
- 4項目全てYES → PASS（深堀りネタとして採用可）
- 1つでもNO → REJECT（別ネタを探す）

---

## 投稿文レビュー基準

### 1. フォーマットチェック
- [ ] 読点（、）が含まれていないか
- [ ] 絵文字が含まれていないか
- [ ] ハッシュタグが含まれていないか
- [ ] 文字数は140文字以内か
- [ ] **引用リンクがツイート本文の直下に配置されているか（CRITICAL）**
- [ ] **ネット上の一次ソースが調査されたか（MANDATORY）** → IndieHackers、Reddit、X.com、公式サイト等のWebSearch実行済みか
- [ ] URLが見つからない場合のみ「なし（内部情報）」となっているか

### 2. 禁止表現チェック
- [ ] AI臭い丁寧語（「〜ですね」「〜と思います」多用）
- [ ] **敬語調の語尾（「〜です」「〜ます」「〜でしょう」）** → 温和な常体のみ許可
- [ ] 伸ばし棒語尾（「〜だよなー」「〜かなー」）
- [ ] 表面的感想（「すごい」「驚いた」だけ）
- [ ] 宣伝臭いリプライ誘導（「みんなどう?」）
- [ ] 当たり前の結論（「継続が大事」「使いこなしの深さが効く」）
- [ ] 宣伝・共有アピール（「〜も納得ですね」「参考になる」「勉強になる」）
- [ ] 数字実績を締めに使用（「259PR出してる」等）
- [ ] レトリカル・クエスチョン（「なぜか?」等の自問自答型）
- [ ] **英文翻訳感・気取ってる感**（カタカナ造語、直訳風表現、海外記事翻訳調）
- [ ] **リスク懸念の過剰言及**（明らかに必要な場合以外の「〜に注意が必要」「〜のリスクもある」）

### 3. 改行チェック（CRITICAL強化）
- [ ] **1つの文・1つの文章塊の途中改行が完全に禁止されているか** → 文章塊内の改行は絶対NG
- [ ] 段落間の改行は意味的区切り時のみか（2段落でも3段落でも内容次第でOK）
- [ ] 読点・接続詞で自牢に文章が繋がれているか（文章塊内で改行で安易に区切っていないか）
- [ ] **短文改行多用で「カッコつけてる」感が出ていないか** → 余白演出・インフルエンサー風・ポエム風・意識高い系NG

### 4. 締め方チェック（CRITICAL）

**「当たり前の結論」禁止ルール**

**問題パターン**:
- 「使いこなしの深さが効く」→ 当たり前すぎる
- 「継続が大事」「質が重要」→ 誰でも言える
- 「〜が効果的」→ 抽象的で新規性なし

**必須チェック**:
1. 締めの文章が「なぜそうなるのか」の本質を突いているか？
   - 現象の裷にある因果関係・メカニズムを説明しているか
   - 読者が「なるほど、そういうことか」と思える洞察があるか

2. 当たり前のことを言っていないか？
   - 「〜が大事」「〜が効く」だけで終わっていないか
   - その結論に至る**起因・理由・メカニズム**が示されているか

3. 新しい知見として価値があるか？
   - 読者が「知らなかった」「そう考えたことなかった」と感じるか
   - 情報の表面ではなく、一段深い洞察があるか

4. **自然な締め方になっているか？**
   - 断定ではなく推測・感想として表現されているか
   - 謙虚な知的好奇心（「こういう見方もあるな」的な姿勢）があるか
   - 独り言的なつぶやき感で、読者への説教ではなく自分の中での気づきを表現しているか
   - 控えめな推測表現・柔らかい評価表現・自然な感情の流れがあるか

5. **詩的・哲学的表現の禁止（CRITICAL - 日本エンジニア界隈向け）**
   - 技術的問題を美化・ロマン化していないか（「〜と引き換えに〜」等の格言調構文はNG）
   - 俯瞰的解説口調・インフルエンサー風深い洞察演出になっていないか（意識高い系感はNG）
   - 問題の深刻さを美化していないか（セキュリティリスクを「選択の問題」として抽象化は実害薄れでNG）
   - **技術的観点からの率直・実務的な感想**になっているか（地味で実践的な視点を重視）
   - 美化しない、ストレートな問題指摘で締めているか

**改善例**:
- ❌「使いこなしの深さが効くってことですね」（断定的、説教的）
- ✅「経験者は『何を聞くべきか』を知ってる。AI活用の差は問いの質で決まるってことかな」（推測的、つぶやき的）

---

### 5. 「宣伝・共有アピール」禁止ルール（CRITICAL - 日本エンジニア界隈向け）

**絶対禁止パターン**:
- 「〜ですね」で終わる「皆さんに共有してますよ」感
- 「〜も納得ですね」「さすがですね」等の実績アピール型の締め
- 数字実績（259PR、月収○万等）を締めに使う
- 「参考になる」「勉強になる」等の読者への訴えかけ

**なぜダメか**:
- 日本のエンジニア界隈は「共有してます」感を嫌う
- 実績アピールは「マウント取り」と感じられる
- 海外向けのトーンは日本向けツイートでは逆効果

**正しい締め方**:
- 技術的洞察で淡々と終わる（敬語禁止）
- 「こういうことか」「なるほど」と読者が自分で思える形
- 実績数字は本文中の補強要素として使う（締めには使わない）
- **温和な常体で締める**（「〜だろう」「〜かも」「〜らしい」「〜ってことか」等）

**例**:
- ❌「30日で259PR出してるのも納得ですね」（敬語・宣伝アピール）
- ❌「参考になるので共有します」（敬語・共有アピール）
- ❌「オーケストレーション税が気になる」（英文翻訳感・気取ってる）
- ✅「並列のボトルネックはモデルじゃなくてファイル競合だった」（常体・淡々）
- ✅「ブランチじゃなくてcheckout分離が正解らしい」（常体・推測調）
- ✅「管理コストがどんな感じなんだろう」（常体・疑問調）

---

### 6. 開発者向け投稿チェック（CRITICAL）
- [ ] 収益数字より技術的差別性を重視しているか → 既存トップツール・競合との比較があるか
- [ ] **競争力の文脈化がされているか** → 新ツール言及時は市場ポジション（メジャー/ニッチ/新興）と競合優位性が明示されているか
- [ ] 抽象概念が具体化されているか → 「配信優位性」→「具体的にどんな手法・仕組みか」まで説明されているか
- [ ] 馴染みのないサービスに文脈説明があるか → 「何をするツールで、どう動作するか」が冒頭で明示されているか
- [ ] 機能性・技術仕様・アーキテクチャの話が中心か
- [ ] ビジネス成果が技術的理由と紐付けられているか（「なぜその技術選択が成果に繋がったか」）

### 7. 複数独立ソースでのクロスチェック（MANDATORY）
- [ ] **日付情報の矛盾確認** → 記事投稿日・初発表日・リポジトリ作成日等の整合性がチェック済みか
- [ ] **複数ソースでの事実確認** → 公式サイト・プレスリリース・X.com・Reddit・HN等で情報の一致を確認済みか
- [ ] **GitHubリポジトリの厳密検証** → 作成日 vs 初コミット日 vs バズ開始日を区別しているか
- [ ] **スター数の時系列変化確認** → 本当に「今日爆発的に伸びた」かタイムライン検証済みか
- [ ] **曖昧な時間表現の具体化** → 「最近」「先週」「January 2026」等を具体的日付に変換済みか
- [ ] **矛盾する日付情報の慎重処理** → 複数の異なる日付が発見された場合、より古い日付を採用しているか

### 8. ペルソナチェック
- [ ] オタク＆AI博識マンらしい視点か
- [ ] 表面的リアクションではなく本質を捉えているか

---

---

## 新フロー位置づけ

**このレビューは第1段階（基本ルールチェック）**
- PASS後に第2段階「tweet-quality-judge（厳しめ有益性レビュー）」を実行
- 最終的にA判定で初めて投稿可能
- **B/C/D判定時は元ネタ変更を積極的に検討** → A判定達成を最優先

---

## 出力フォーマット

```
## 鮮度判定結果

**ネタ**: [ネタのタイトル]
**記事投稿日**: [YYYY-MM-DD]
**初発表日**: [YYYY-MM-DD]（← こちらが基準）
**経過日数**: [N日]（初発表日からの経過）
**今日の日付**: [YYYY-MM-DD]

### 鮮度判定: [PASS/REJECT]

**理由**:
- [判定理由を具体的に記載]

**深堀り判定（4日以上の場合）**:
- AIパワーユーザー向け新知見: [YES/NO] - [理由]
- 個人開発者向け実用2次情報: [YES/NO] - [理由]
- 焼き直しではない: [YES/NO] - [理由]
- 最新バージョンか: [YES/NO] - [理由]

---

## レビュー結果

### 投稿文判定: [PASS/REJECT]

### 問題点（REJECTの場合）
1. [問題点1]
2. [問題点2]

### クロスチェック結果（情報鮮度関連のみ）
- **日付情報検証**: [完了/問題あり] - [結果詳細]
- **複数ソース確認**: [完了/問題あり] - [結果詳細]
- **GitHubリポジトリ検証**: [完了/問題あり/非該当] - [結果詳細]

### 修正版（REJECTの場合）
[修正後のツイート文]

**推奨アクション**: [採用/却下して別ネタ探し/修正して再レビュー]
```

---

## 注意事項
- **記事投稿日と初発表日は別物** → 必ず初発表日を調査する
- 日付の特定が曖昧な場合は、WebSearchで正確な日付を調査する
- 「約1週間前」などの曖昧表現は正確な日付に変換する
- 判定に迷った場合は厳しい方（REJECT）を選ぶ
- **複数独立ソースでのクロスチェックを必ず実施** → 矛盾する日付情報がある場合は慎重に扱う
- **AIパワーユーザーの厳しい鮮度基準を適用** → 3-4日前の情報は「古いネタ」と認識される
- **表面的な「今日公開」情報は疑ってかかる** → 数日前の情報を今日記事化しただけの場合が多い
