# Indie Voice Tweet - AI開発者の声からツイート生成

## 役割
r/vibecoding・Hacker News等から収集したAI開発者のリアルな体験談（失敗談・成功体験・学び）を元に、
共感を呼ぶ日本語ツイートを生成する。

## 実行手順

### ステップ0: ペルソナ情報読み込み（MANDATORY）

**ツイート生成前に必ず以下のファイルを読み込む:**

```
C:\Users\Tenormusica\persona-db\data\tone.json      # 口調・語尾・避けるべき表現
C:\Users\Tenormusica\persona-db\data\stances.json   # スタンス・価値観
C:\Users\Tenormusica\persona-db\data\interests.json # 興味の境界線
C:\Users\Tenormusica\persona-db\data\tools.json     # 使用ツール
C:\Users\Tenormusica\persona-db\data\knowledge.json # 知識レベル
```

### ステップ1: データ収集

**Reddit（要API認証）:**
```bash
cd C:\Users\Tenormusica\x-auto
python indie_voice_main.py --prepare --subreddits vibecoding --sort hot --limit 30
```

**Hacker News（認証不要）:**
```python
from indie_voice.collectors import HackerNewsCollector
collector = HackerNewsCollector()
posts = collector.collect_ai_indie_stories(limit=20)
```

**出力される候補データを確認:**
- `indie_voice/data/tweet_candidates_*.json`
- `indie_voice/data/hn_posts_*.json`

### ステップ2: ツイート素材選定

収集した候補から以下の優先順位で選定:

| 優先度 | 条件 |
|--------|------|
| 1位 | 具体的な数字あり + 感情的インパクト大（失敗→回復、意外な成功） |
| 2位 | AI開発あるある（多くの人が共感できる体験） |
| 3位 | 実践的なTips・学び（すぐ使える知見） |
| 4位 | 議論を呼ぶ意見（賛否分かれる主張） |

**採用すべき体験談:**
- 「3日かかると思ったら2時間で終わった」系の意外性
- 「AIを信用しすぎて痛い目にあった」系の失敗談
- 「実はAIより手書きの方が速かった場面」系の逆説
- 「深夜2時にバグが直った時の喜び」系の感情的瞬間

**避けるべき内容:**
- 抽象的な感想のみ（「AIすごい」だけ）
- 企業・製品の宣伝色が強いもの
- 技術的詳細がないもの

---

### ステップ2.3: ペルソナ立場に基づくコンテンツ視点選定（CRITICAL）

**🚨 ペルソナはAIエージェント推進のソロプレナー・個人開発者**

#### 視点の優先順位

| 優先度 | 視点 | 割合目安 | 例 |
|--------|------|----------|-----|
| 1位 | **AI推進・建設的** | 80% | こうすると上手くいく、これで効率化できた |
| 2位 | **AI批判的（価値ある場合のみ）** | 20% | 関係者に是非知っておいてほしいレベルの知見 |

#### AI批判的コンテンツの採用基準

批判的視点のツイートは以下の条件を**すべて満たす場合のみ**採用:

1. **関係者に是非知っておいてほしいレベルの価値がある**
2. **「問題がある→こうした方がいい」という建設的な結論がある**
3. **常識的じゃないレベルのナレッジが含まれている**

**❌ 却下すべき批判的コンテンツ:**
- 単なるAI批判（問題点の列挙のみ）
- 解決策がないネガティブな話
- ペルソナの立場と矛盾する内容

**✅ 採用すべき批判的コンテンツ:**
- 「この問題に遭遇したからこうした（常識的じゃないレベルのナレッジ）」
- 「こういう問題があるからこうした方がいいよね」
- 失敗から得た具体的な学び・対策

---

### ステップ2.4: 視点の一貫性チェック（伝聞 vs 本人視点）

**🚨 伝聞トーンと主観評価の混在は日本人に違和感を与える**

#### 混在NGパターン

```
❌ 「〜したらしい」（伝聞）+ 「デカい」「ヤバい」（主観評価）
   → 他人の成果を主観的に評価するのは日本人好みじゃない

❌ 「〜した人がいる」（第三者視点）+ 「マジで助かる」（本人感情）
   → 視点が一貫していない
```

#### 視点別の適切な締め方

| 視点 | 適切な締め方 | 不適切な締め方 |
|------|-------------|---------------|
| 伝聞（〜らしい） | 「参考になる」「興味深い」 | 「デカい」「ヤバい」「マジで」 |
| 本人視点 | 「デカい」「助かる」「分かった」 | 「らしい」「という話」 |
| 引用（〜と言ってた） | 「なるほど」「確かに」 | 感情的評価 |

#### 修正例

```
❌ 2晩で完了したらしい / そこをAIが埋めてくれたのがデカい
   → 伝聞なのに主観評価

✅ 2晩で完了したらしい / AIがドキュメント学習を代替した形
   → 伝聞トーンで一貫

✅ 2晩で完了した / そこをAIが埋めてくれたのがデカい
   → 本人視点で一貫
```

---

### ステップ2.5: Why情報抽出（CRITICAL - 最重要）

**🚨 事実の羅列だけでは「ためになる」ツイートにならない**

素材選定後、ツイート生成前に必ず以下の「Why情報」を元ネタから抽出する。
Why情報が含まれていない素材は**素材として不適格**と判断し、別の素材を選定する。

#### Why情報チェックリスト

| Whatの事実 | 必須のWhy情報 | 質問例 |
|-----------|--------------|--------|
| 「X日で完了した」 | **なぜその期間で完了できたのか** | 何が要因？どの部分が効率化された？ |
| 「X%の失敗率」 | **なぜその数字が問題なのか** | 何と比較して高い/低い？影響は？ |
| 「山ほど作って失敗した」 | **何を学んだのか** | 何が変わった？どんな知見を得た？ |
| 「成功した」 | **なぜうまくいったのか** | 何が違った？どの判断が良かった？ |
| 「失敗した」 | **なぜ失敗したのか** | 原因は？何が足りなかった？ |

#### Why情報の抽出方法

1. **元ネタ原文から抽出**: 投稿者が理由を述べている箇所を探す
2. **コメント欄から補完**: 原文になければコメント欄の議論から補完
3. **元記事（リンク先）から抽出**: URLがある場合はリンク先を確認

#### Why情報がない場合の対応

- **元ネタにWhy情報がない** → その素材は不採用、別の素材を選定
- **Why情報が曖昧** → 元記事を深掘りするか、別の素材を選定
- **Why情報はあるが長い** → 核心部分を抽出して簡潔に

#### Why情報の品質基準

**良いWhy情報:**
```
✅ 「カーネルAPIの置き換えをAIが自動提案してくれたから2晩で完了した」
   → 具体的な理由が明確。読者が再現可能な知見。

✅ 「5-10%の失敗率だと、ユーザーは毎日1回は失敗を経験する。それが不信感に繋がった」
   → なぜその数字が問題かが明確。因果関係が分かる。
```

**悪いWhy情報（= Whyがない）:**
```
❌ 「2晩で完了した」
   → What（事実）のみ。なぜ速かったか不明。

❌ 「失敗率が高かった」
   → 何と比較して高いか不明。影響も不明。
```

---

### ステップ3: ツイート生成

**【基本ルール】**
- 日本語140文字に近づける
- 読点（、）完全禁止 → 改行のみ
- 絵文字0個（完全禁止）
- ハッシュタグ禁止
- 敬語禁止 → 温和な常体で

**【表記ルール】**

| 略語 | 正式表記 | 備考 |
|------|----------|------|
| HN | Hacker News | 省略せず正式名称を使用 |
| CC | Claude Code | 省略可だが文脈で判断 |
| GH | GitHub | 省略可だが文脈で判断 |

**【スペースルール - CRITICAL】**

固有名詞は**スペースなしで崩す**（公式表記より人間らしさ優先）:

```
✅ vibecodingするなら
✅ ClaudeCodeに3000行出させて
✅ TypeScriptがいい

❌ vibe coding するなら
❌ Claude Code に3000行出させて
❌ vibe codingするなら（固有名詞内のスペースも除去）
```

**理由**: 公式表記に合わせすぎるとAI感が出る。崩した方が人間らしい。

**【Indie Voice 専用トーン】**
- **共感ベース**: 「わかる」「あるある」と思わせる
- **具体性重視**: 数字・ツール名・期間を含める
- **人間味**: 完璧じゃない、未解決の部分も残す
- **自分事として語る**: 「らしい」「って話」ではなく「自分も〜」「〜だった」

---

## 主張の強さ調整ガイド（CRITICAL - 反響を得るための基準）

### ツイートは「少し驚かれる内容」の方が評価される

**🎯 目指すべき主張レベル:**

| レベル | 説明 | 判定 |
|--------|------|------|
| 弱すぎ | 誰でも知ってる一般論、抽象的すぎ | ❌ 反響なし |
| 適切 | **9割の人が肯定する若干過剰な主張** | ✅ ボーダーライン内側 |
| 強すぎ | 明らかな嘘、裏が取れない極論 | ❌ 信用を失う |

### 具体例

```
❌ 弱すぎ（一般論）
「SPECファイルを詳しめに書いておく」
「シンプルな構成を明示する方が通りやすい」
→ 誰でも言える。具体的な用語がない。驚きがない。

✅ 適切（8割が肯定する若干過剰）
「SPECファイルを500語くらいで書くとone-shot実装が可能」
「PHP/SQLみたいなシンプル構成だと成功率が上がる」
→ 具体的な数字・技術名がある。少し驚きがある。

❌ 強すぎ（信用を失う）
「SPECファイルさえあれば100%一発で動く」
「フレームワークは絶対に指定するな」
→ 明らかに例外がある。嘘になる。
```

### レビュー時の判定基準

**「言い過ぎ」かどうかの判定:**
1. **9割の人が肯定するか？** → Yes なら許容
2. **有益な知識として成立するか？** → Yes なら許容
3. **明らかな嘘になっていないか？** → No なら許容

**「抽象的すぎ」かどうかの判定:**
1. **具体的な数字があるか？** → ない場合は要検討
2. **具体的な技術名・ツール名があるか？** → ない場合は要検討
3. **誰でも言える一般論になっていないか？** → なっている場合はNG

### 修正の方向性

| 問題 | 修正方向 |
|------|----------|
| 言い過ぎ | 限定的な表現に（「〜の場合は」「〜なら」） |
| 抽象的すぎ | 具体的な数字・技術名を追加 |
| 一般論 | 意外性のある主張に変更 |

---

## 語尾・表現の使い分けガイド（CRITICAL）

### 「〜んだよね」の正しい使い方

**使う場面:**
- **既知の事実を共有する時**: 自分が前から知っていて、相手も知っているだろう内容
- **経験則に基づく確信がある時**: 何度も経験して分かっていること
- **蓄積された意見を出力する時**: 今気づいたのではなく、前から思っていたこと
- **断定するが押しつけがましくない時**: 「俺はこう思う」を柔らかく伝える

**使わない場面:**
- ❌ **新しい発見・驚きを表現する時**: 「〜なんだ」「〜だな」「〜だ…」が適切
- ❌ **感心・関心を示す時**: 「〜なんだ」「〜とは思わなかった」が適切
- ❌ **初めて知った情報を伝える時**: 「〜らしい」「〜だって」が適切

**例（正しい使い方）:**
```
✅ AIって新規開発には強いけどレガシーは苦手なんだよね
   → 経験則。何度もやって分かっていること。蓄積された意見。

✅ Claude Codeで3日溶かすことあるんだよね
   → 複数回経験している。前から思っていたこと。
```

**例（間違った使い方）:**
```
❌ 価格差ここまで開くんだよね
   → 驚き・発見の文脈なのに「前から知ってた」トーンになっている。矛盾。

✅ 価格差ここまで開くんだ…
   → 驚き・発見を素直に表現。

✅ 価格差こんなにあるとは思わなかった
   → 感心を表現。
```

### 感情別・語尾対応表

| 感情 | 適切な語尾 | 不適切な語尾 |
|------|-----------|-------------|
| 驚き・発見 | 「〜んだ」「〜だ…」「〜とは」 | 「〜だよね」 |
| 経験則・確信 | 「〜んだよね」「〜ではある」 | 「〜らしい」 |
| 感心・関心 | 「〜なんだな」「〜とは思わなかった」 | 「〜だよね」 |
| 共感の誘い | 「〜だよね」「〜あるよね」 | 「〜なんだ」 |
| 学び・教訓 | 「〜だなと」「〜と分かった」 | 「〜だよね」 |

---

**【フォーマット例】**

```
[体験の導入（状況説明）]

[具体的な数字・事実]

[感想・学び・オチ]
```

**【良い例】**
```
Claude Codeでレガシーコード触ったら3日溶かした

AIが提案する修正が別のバグを生む無限ループ
結局30分で書けるはずの関数に8時間

新規開発では神だけど既存コードは要注意
```

**【悪い例】**
```
AIコーディングツールを使ってみた感想ですね

とても便利だと思いました
皆さんも試してみてはいかがでしょうか

#AI #プログラミング
```

---

### ステップ4: サブエージェントレビュー（MANDATORY）

**ツイート生成後、必ず以下の3つのレビューをサブエージェントで実行:**

#### 4-1. 真偽調査レビュー（CRITICAL）
```
Task(subagent_type="general-purpose",
     prompt="以下のツイート内の事実・数値を検証してください。

     【ツイート】
     [TWEET_TEXT]

     【元ネタ原文】
     [ORIGINAL_TEXT]

     【検証項目】
     1. 価格情報は原文と一致しているか
     2. 数値（期間・金額・件数）は正確か
     3. ツール名・サービス名は正確か
     4. 文脈の読み落としがないか（条件付きの話を断定していないか）
     5. 現在のサービス仕様と矛盾していないか

     【出力】
     - 検証結果: OK / NG
     - 問題点（あれば）
     - 修正案（あれば）")
```

#### 4-2. 言語チェックレビュー
```
Task(subagent_type="general-purpose",
     prompt="以下のツイートの言語・表現を検証してください。

     【ツイート】
     [TWEET_TEXT]

     【検証項目】
     1. 語尾の使い方は感情と一致しているか
        - 驚き・発見 → 「〜んだ」「〜だ…」
        - 経験則 → 「〜んだよね」
        - 感心 → 「〜なんだな」「〜とは思わなかった」
     2. 敬語が混入していないか
     3. AI的な表現（「〜んだな」=今気づいた感）になっていないか
     4. 読点（、）が入っていないか

     【出力】
     - 検証結果: OK / NG
     - 問題点（あれば）
     - 修正案（あれば）")
```

#### 4-3. フォーマットレビュー
```
Task(subagent_type="general-purpose",
     prompt="以下のツイートのフォーマットを検証してください。

     【ツイート】
     [TWEET_TEXT]

     【検証項目】
     1. 文字数は140文字以内か
     2. 絵文字が入っていないか
     3. ハッシュタグが入っていないか
     4. 改行の位置は適切か
     5. 略語は正式表記になっているか（HN→Hacker News等）

     【出力】
     - 検証結果: OK / NG
     - 問題点（あれば）
     - 修正案（あれば）")
```

#### 4-4. Why情報レビュー（CRITICAL - 最重要）
```
Task(subagent_type="general-purpose",
     prompt="以下のツイートに「ためになる知見（Why情報）」が含まれているか検証してください。

     【ツイート】
     [TWEET_TEXT]

     【元ネタ原文】
     [ORIGINAL_TEXT]

     【Why情報の定義】
     - 「なぜそうなったか」の因果関係
     - 「何を学んだか」の具体的知見
     - 読者が再現・応用できる情報

     【検証項目】
     1. 事実の羅列だけになっていないか
        - ❌ 「2日で完了した」だけ → なぜ2日で完了できたかが必要
        - ❌ 「失敗率5%」だけ → なぜそれが問題かが必要
     2. Why情報は元ネタに基づいているか（創作していないか）
     3. Why情報は読者にとって再現・応用可能か
     4. 因果関係が明確か（AだからBになった）

     【What vs Why の判定基準】
     - What（事実）: 「X日で完了」「Y%の失敗率」「Z個作った」
     - Why（知見）: 「〜だから速かった」「〜が原因で失敗」「〜を学んだ」

     【出力】
     - Why情報の有無: あり / なし
     - 抽出されたWhy情報: [具体的に記載]
     - 検証結果: OK / NG
     - 問題点（あれば）
     - 修正案（あれば）")
```

### ステップ5: セルフチェック

**サブエージェントレビュー後、最終セルフチェック:**
- [ ] 真偽調査レビュー: OK
- [ ] 言語チェックレビュー: OK
- [ ] フォーマットレビュー: OK
- [ ] **Why情報レビュー: OK**（最重要）
- [ ] 具体的な数字・期間が入っているか
- [ ] AIツール名が正確か
- [ ] 共感できる体験になっているか
- [ ] 宣伝臭くないか
- [ ] **読者にためになる知見（Why情報）が含まれているか**

### ステップ6: 出力

```
## 投稿文

[ツイート本文]

---

**文字数**: [N]文字
**元ネタ**: Hacker News / Reddit r/vibecoding [post_id]
**カテゴリ**: [failure/success/learning]
**元投稿URL**: [URL]
**レビュー結果**: 真偽OK / 言語OK / フォーマットOK / **WhyOK**
**抽出したWhy情報**: [ツイートに含めた具体的な知見を記載]
**品質判定**: [A/B/C/D]
```

---

## 定期実行設定

Task Schedulerで以下を設定:
- 頻度: 毎日 or 週3回
- 実行: `claude -p "C:\Users\Tenormusica\x-auto\skills\indie-voice-tweet\PROMPT.md を読んで実行"`
