# x-auto TODO

## PENDING: ツイート効果評価ツール

generate-tweetから分離した投稿効果の定量評価システム。

### 背景
- 元々generate-tweet内に重みスコア（リプライ誘発13.5 / プロフィールクリック12.0 / フォロー獲得4.0）があったが、出典不明かつ生成時の実効性が低いため削除
- 投稿効果の評価は生成時ではなく**投稿後の独立した評価ツール**として構築すべき

### 評価の難しさ
- 投稿時間的要因（時間帯・曜日でリーチが変わる）
- 流行り廃り（トレンドに乗ったかどうか）
- 既存ファンのリアクション有無（フォロワー基盤の影響）
- 多要素が絡むため一概な評価は困難

### 方針
- **自分のツイートの評価は外れ値が多い**（フォロワー少・サンプル少）
- **他インフルエンサーのツイート評価の方が外れ値が少ない**
- 他者のツイートを分析して「何がウケるか」のパターンを抽出する方向が有効

---

## TODO: 他インフルエンサーのツイート集約・分析システム

他のAI/エンジニア系インフルエンサーの最新ツイートを集約し、良い内容だけ抽出してツイート作成に活用する仕組み。

### 想定フロー
1. 対象インフルエンサーリストの定義
2. 最新ツイートの定期収集（X API or スクレイピング）
3. エンゲージメント指標でフィルタリング（いいね数・RT数・リプライ数）
4. 内容の分析・パターン抽出
5. 抽出した知見をgenerate-tweetのネタ選定に反映

### 優先度
近々着手予定

---

## TODO: content_evaluator.py 拡張

### 好感度/レピュテーションリスク判定
- 「インプは高いが反感を買う」パターンの検出
- 低品質AI生成画像 + 誤情報の組み合わせ（一瞬バズるが信頼を毀損）
- 煽り系・二次利用感のあるコンテンツのリスクスコア化
- weighted_scoreだけでは捉えられない「質的な評価」軸

### AIエージェントSEO適性の精度向上
- ai_citation_value（現状1-5のLLM推測）をより具体的な基準に
- 「AIが一次ソースとして引用したくなるか」の定量的指標
- 独自データ・独自体験・再現可能な手順を含むかどうか

### コンテンツ戦略の方向性
- **ニュース主軸は避ける** — 二次利用感が出やすく、飽和度判定も困難
- **BIP（Build in Public）を主軸に** — 独自体験は代替不可、潜在的信頼スコア蓄積
- **AI how-to/チュートリアル** — 再現可能な具体手順は一次ソース価値が高い
- news系ツイートの評価優先度を下げ、BIP/how-toの分析精度を上げる

### ニュース飽和度の定量化（将来）
- 現状はGroq LLMの推測のみ
- twscrapeで同トピックの既存ツイート件数を実測する方式
- buzz-tweets-latest.json / key_persons.json との照合
